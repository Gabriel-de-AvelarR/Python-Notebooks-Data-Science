{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HaabIE4ETRhY"
      },
      "source": [
        "# SCC-ICMC-USP - 2º Semestre de 2023\n",
        "## SCC0275 - Introdução à Ciência de Dados\n",
        "### Professora: Roseli A. F. Romero\n",
        "### Monitor: Roseval Malaquias Jr\n",
        "\n",
        "### **Exercício 6**\n",
        "\n",
        "**Número do Grupo:**\n",
        "\n",
        "**Alunos:**\n",
        "1. Renan de Almeida Leandro - 11801157\n",
        "2. Gabriel de Avelar Las Casas Rebelo - 11800462\n",
        "\n",
        "Nesta atividade, nosso objetivo é exercitar os seguintes conceitos:\n",
        "- Entender modelagem de dados;\n",
        "- Entender o processo de avaliação;\n",
        "- Trabalhar com procedimentos de amostragem;\n",
        "- Trabalhar com várias medidas de avaliação.\n",
        "\n",
        "---\n",
        "\n",
        "**Escolha, entre as opções abaixo, apenas UM dataset para realizar os exercícios.**\n",
        "\n",
        "**Se o dataset escolhido tiver mais de duas classes, transforme ele num problema binário. Isso pode ser feito escolhendo uma classe para representar a classe positiva e o restante a classe negativa.**\n",
        "\n",
        "**Possíveis datasets:**\n",
        "\n",
        "\n",
        "*   **Câncer de mama:** [sklearn.datasets.load_breast_cancer](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_breast_cancer.html#sklearn.datasets.load_breast_cancer)\n",
        "*   **Dígitos:** [sklearn.datasets.load_digits](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_digits.html#sklearn.datasets.load_digits)\n",
        "*   **Wine:** [sklearn.datasets.load_wine](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_wine.html#sklearn.datasets.load_wine)\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "Após a análise dos dados e um pré-processamento, segue a etapa de modelagem dos experimentos. Essa etapa pode exigir um retorno ao pré-processamento, caso seja percebido que algo precisa ser ajustado. A modelagem visa determinar as etapas da execução dos experimentos. No nosso cenário, o experimento é a utilização de algoritmos de classificação, regressão ou agrupamento. Para tanto, é preciso definir, com a ajuda da análise dos dados, o tipo do problema (classificação, regressão, ...), os atributos/features a serem utilizados e o processo de avaliação.\n",
        "\n",
        "Esta prática foca mais no processo de avaliação. Para a avaliação, é necessário definir qual a função de custo/erro adequada e qual o estimador para o desempenho.\n",
        "\n",
        "Utilizaremos medidas de desempenho para classificação binária baseadas na matriz de confusão (TFP, TFN, TVP, TVN).\n",
        "\n",
        "Nas aplicações reais, o cliente dita qual a medida de desempenho deve ser utilizada, e muitas vezes não é uma das clássicas. E como essa medida, em geral, tem um impacto grande no treinamento do algoritmo de classificação, muitas vezes o algoritmo precisa ser adaptado e isso não é uma tarefa fácil.\n",
        "\n",
        "Após a definição do tipo do problema e da medida de avaliação, é preciso definir como será estimado o desempenho final.\n",
        "\n",
        "Esse processo está ligado à escolha do algoritmo de classificação, bem como à escolha de alguns hiperparâmetros. Uma abordagem muito comum na área é a utilização do 10-fold Cross-Validation. Esse procedimento pode ser utilizado para estimar o desempenho do classificador final, bem como, na escolha de alguns poucos hiperparâmetros.\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_YGNezFvvnES"
      },
      "source": [
        "### Questão 01.\n",
        "\n",
        "- Caso a base escolhida tenha mais de 2 classes, transforme-a em um problema binário. Você pode fazer isso uma vez e depois usar a nova base nas próximas questões.\n",
        "\n",
        "- Outras operações como remoção de atributos podem ser feitas uma vez fora da função de pré-processamento.\n",
        "\n",
        "- Implemente a função de pré-processamento para sua base aplicando as técnicas que achar necessário.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importando as bibliotecas necessárias\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "from sklearn.metrics import precision_score, recall_score"
      ],
      "metadata": {
        "id": "HU8365lVMzLu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#O dataset escolhido foi o que contem dados sobre Cancer de Mama.\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "\n",
        "dataset = load_breast_cancer()\n",
        "dataset.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ca2tCts9FylM",
        "outputId": "56b722ee-7c6f-411a-b020-9dbc009efbdc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename', 'data_module'])"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Analisando o conteúdo do dataset:\n",
        "print(dataset['DESCR'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XkJzWNmmG4E5",
        "outputId": "b7097676-f335-4310-97a8-af011559afc3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".. _breast_cancer_dataset:\n",
            "\n",
            "Breast cancer wisconsin (diagnostic) dataset\n",
            "--------------------------------------------\n",
            "\n",
            "**Data Set Characteristics:**\n",
            "\n",
            "    :Number of Instances: 569\n",
            "\n",
            "    :Number of Attributes: 30 numeric, predictive attributes and the class\n",
            "\n",
            "    :Attribute Information:\n",
            "        - radius (mean of distances from center to points on the perimeter)\n",
            "        - texture (standard deviation of gray-scale values)\n",
            "        - perimeter\n",
            "        - area\n",
            "        - smoothness (local variation in radius lengths)\n",
            "        - compactness (perimeter^2 / area - 1.0)\n",
            "        - concavity (severity of concave portions of the contour)\n",
            "        - concave points (number of concave portions of the contour)\n",
            "        - symmetry\n",
            "        - fractal dimension (\"coastline approximation\" - 1)\n",
            "\n",
            "        The mean, standard error, and \"worst\" or largest (mean of the three\n",
            "        worst/largest values) of these features were computed for each image,\n",
            "        resulting in 30 features.  For instance, field 0 is Mean Radius, field\n",
            "        10 is Radius SE, field 20 is Worst Radius.\n",
            "\n",
            "        - class:\n",
            "                - WDBC-Malignant\n",
            "                - WDBC-Benign\n",
            "\n",
            "    :Summary Statistics:\n",
            "\n",
            "    ===================================== ====== ======\n",
            "                                           Min    Max\n",
            "    ===================================== ====== ======\n",
            "    radius (mean):                        6.981  28.11\n",
            "    texture (mean):                       9.71   39.28\n",
            "    perimeter (mean):                     43.79  188.5\n",
            "    area (mean):                          143.5  2501.0\n",
            "    smoothness (mean):                    0.053  0.163\n",
            "    compactness (mean):                   0.019  0.345\n",
            "    concavity (mean):                     0.0    0.427\n",
            "    concave points (mean):                0.0    0.201\n",
            "    symmetry (mean):                      0.106  0.304\n",
            "    fractal dimension (mean):             0.05   0.097\n",
            "    radius (standard error):              0.112  2.873\n",
            "    texture (standard error):             0.36   4.885\n",
            "    perimeter (standard error):           0.757  21.98\n",
            "    area (standard error):                6.802  542.2\n",
            "    smoothness (standard error):          0.002  0.031\n",
            "    compactness (standard error):         0.002  0.135\n",
            "    concavity (standard error):           0.0    0.396\n",
            "    concave points (standard error):      0.0    0.053\n",
            "    symmetry (standard error):            0.008  0.079\n",
            "    fractal dimension (standard error):   0.001  0.03\n",
            "    radius (worst):                       7.93   36.04\n",
            "    texture (worst):                      12.02  49.54\n",
            "    perimeter (worst):                    50.41  251.2\n",
            "    area (worst):                         185.2  4254.0\n",
            "    smoothness (worst):                   0.071  0.223\n",
            "    compactness (worst):                  0.027  1.058\n",
            "    concavity (worst):                    0.0    1.252\n",
            "    concave points (worst):               0.0    0.291\n",
            "    symmetry (worst):                     0.156  0.664\n",
            "    fractal dimension (worst):            0.055  0.208\n",
            "    ===================================== ====== ======\n",
            "\n",
            "    :Missing Attribute Values: None\n",
            "\n",
            "    :Class Distribution: 212 - Malignant, 357 - Benign\n",
            "\n",
            "    :Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian\n",
            "\n",
            "    :Donor: Nick Street\n",
            "\n",
            "    :Date: November, 1995\n",
            "\n",
            "This is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.\n",
            "https://goo.gl/U2Uwz2\n",
            "\n",
            "Features are computed from a digitized image of a fine needle\n",
            "aspirate (FNA) of a breast mass.  They describe\n",
            "characteristics of the cell nuclei present in the image.\n",
            "\n",
            "Separating plane described above was obtained using\n",
            "Multisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\n",
            "Construction Via Linear Programming.\" Proceedings of the 4th\n",
            "Midwest Artificial Intelligence and Cognitive Science Society,\n",
            "pp. 97-101, 1992], a classification method which uses linear\n",
            "programming to construct a decision tree.  Relevant features\n",
            "were selected using an exhaustive search in the space of 1-4\n",
            "features and 1-3 separating planes.\n",
            "\n",
            "The actual linear program used to obtain the separating plane\n",
            "in the 3-dimensional space is that described in:\n",
            "[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\n",
            "Programming Discrimination of Two Linearly Inseparable Sets\",\n",
            "Optimization Methods and Software 1, 1992, 23-34].\n",
            "\n",
            "This database is also available through the UW CS ftp server:\n",
            "\n",
            "ftp ftp.cs.wisc.edu\n",
            "cd math-prog/cpo-dataset/machine-learn/WDBC/\n",
            "\n",
            ".. topic:: References\n",
            "\n",
            "   - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction \n",
            "     for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on \n",
            "     Electronic Imaging: Science and Technology, volume 1905, pages 861-870,\n",
            "     San Jose, CA, 1993.\n",
            "   - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and \n",
            "     prognosis via linear programming. Operations Research, 43(4), pages 570-577, \n",
            "     July-August 1995.\n",
            "   - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques\n",
            "     to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) \n",
            "     163-171.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observa-se que o dataset é composto por:\n",
        "- 30 features (variaveis numericas)\n",
        "- 1 target (variavel alvo), classificado entre 'malignant' e 'benign'\n",
        "\n",
        "Observa-se também que há um bom balanceamento entre as classes. Desta forma, como pré-processamento, somente será realizada a normalização dos dados."
      ],
      "metadata": {
        "id": "3DBWD-jFLj3b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Criando o dataframe:\n",
        "df = pd.DataFrame(data=dataset['data'], columns=dataset['feature_names'])\n",
        "\n",
        "df['target'] = dataset['target']"
      ],
      "metadata": {
        "id": "uy8wo9niJrDp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IXyPAd32wZq4"
      },
      "source": [
        "# Complete a função de pré-processamento.\n",
        "def preprocess(x_treino, x_teste, y_treino, y_teste):\n",
        "\n",
        "  # Normalizando os dados da base:\n",
        "\n",
        "    scaler = StandardScaler()\n",
        "    x_treino_novo = scaler.fit_transform(x_treino)\n",
        "    x_teste_novo = scaler.transform(x_teste)\n",
        "\n",
        "    y_treino_novo = y_treino\n",
        "    y_teste_novo = y_teste\n",
        "\n",
        "\n",
        "    return x_treino_novo, x_teste_novo, y_treino_novo, y_teste_novo"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### Questão 02.\n",
        "\n",
        "Implemente a função que retorna a matriz de confusão, escolha duas métricas de avaliação e crie 2 funções, sendo  uma função para cada métrica calculada a partir da matriz confusão."
      ],
      "metadata": {
        "id": "AoWo_N9Lkukt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "o_OSMi4zQDns"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Complete a função de cálculo da matriz de confusão.\n",
        "def confusion_matrix(y_test, y_pred):\n",
        "\n",
        "    TP = np.sum((y_test == 1) & (y_pred == 1))\n",
        "    TN = np.sum((y_test == 0) & (y_pred == 0))\n",
        "    FP = np.sum((y_test == 0) & (y_pred == 1))\n",
        "    FN = np.sum((y_test == 1) & (y_pred == 0))\n",
        "\n",
        "    conf = np.zeros((2,2))\n",
        "    conf = np.array([[TP, FP], [FN, TN]])\n",
        "\n",
        "    return conf"
      ],
      "metadata": {
        "id": "hKc6ZCyZkvva"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Demonstra o funcionamento da função confusion_matrix.\n",
        "actual    = np.array([1, 0, 1, 1, 0, 0, 1, 0, 1, 1])\n",
        "predicted = np.array([0, 1, 1, 1, 1, 0, 1, 1, 0, 1])\n",
        "\n",
        "conf_mat = confusion_matrix(actual, predicted)\n",
        "print(conf_mat)"
      ],
      "metadata": {
        "id": "OAzpcPmORVHM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5dbbfe5d-7659-4f76-ac45-0748fd645ae0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[4 3]\n",
            " [2 1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mudar o nome e os parâmetros da função de acordo com sua métrica 1.\n",
        "def metricPrecision(conf_mat):\n",
        "    TP, FP, FN, TN = conf_mat.ravel()  # Use ravel() para obter uma versão achatada da matriz\n",
        "    return TP / (TP + FP)\n",
        "\n",
        "# Chame a função de precisão com a matriz de confusão\n",
        "precision = metricPrecision(conf_mat)\n",
        "print(precision)"
      ],
      "metadata": {
        "id": "jMZQRN9FOZDF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a706bfc-6473-4ab3-c444-51fa82b3dbb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5714285714285714\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mudar o nome e os parâmetros da função de acordo com sua métrica 2.\n",
        "def metricRecall(conf_mat):\n",
        "    TP, FP, FN, TN = conf_mat.ravel()\n",
        "    return TP / (TP + FN)\n",
        "\n",
        "recall = metricRecall(conf_mat)\n",
        "print(recall)"
      ],
      "metadata": {
        "id": "iwIJaOOaOqME",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "adf0548f-1021-4553-b651-c0c9c45e9de2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6666666666666666\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l28MiSJ8tEzb"
      },
      "source": [
        "---\n",
        "### Questão 03.\n",
        "\n",
        "Complete e execute a função *classificacao* definida no notebook.\n",
        "\n",
        "- Aplique validação cruzada\n",
        "- Use sua função de pré-processamento\n",
        "- Use suas métricas de avaliação\n",
        "\n",
        "**ATENÇÃO:** utilizar o método ``sklearn.model_selection.KFold`` para realizar a amostragem solicitada. Prestem atenção nas dicas e complete o código onde foi solicitado."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7eU824MhsLjR"
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import KFold\n",
        "from matplotlib import pyplot as plt\n",
        "from numpy import mean, std\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def classificacao(data, columns, target, preproc_fn, score_fn, score_name,\n",
        "                  folds=5, plot=True):\n",
        "    \"\"\"\n",
        "    Executa classificação do conjunto de dados passado\n",
        "    ---------------------------------------------------------------\n",
        "    data:       DataFrame. Conjunto de dados\n",
        "    columns:    Lista de inteiros. Índice das colunas utilizadas no treinamento e teste\n",
        "    target:     Inteiro. Índice da coluna alvo\n",
        "    preproc_fn: Função. Faz o pré-processamento da base já separada em treino e teste\n",
        "    score_fn:   Função. A função que calcula a medida de desempenho desejada. Deve ser uma\n",
        "                função que compara dois vetores, o primeiro vetor são os valores preditos\n",
        "                pelo classificador, o segundo os rótulos reais\n",
        "                Vide exemplo das funções em\n",
        "                http://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics\n",
        "                como por exemplo, sklearn.metrics.accuracy_score\n",
        "                http://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html\n",
        "    score_name: String. Uma string com o nome da medida de desempenho\n",
        "    folds:      Inteiro. Número de folds na validação cruzada\n",
        "    plot:       Booleano. True para plotar os gráficos False para não plotar\n",
        "    ---------------------------------------------------------------\n",
        "    Realiza a classificação em 2 modelos (knn, Árvore de decisão)\n",
        "    Plot o gráfico de desempenho para cada classificador.\n",
        "    Retorna um dicionário com os classificadores treinados, as medidas de desempenho e matriz de confusão\n",
        "    \"\"\"\n",
        "    # inicializa os modelos com os parâmetros solicitados\n",
        "    knn = KNeighborsClassifier(n_neighbors=3)\n",
        "    dt = DecisionTreeClassifier(criterion='gini', splitter='best', min_samples_split=int(len(data)*0.1))\n",
        "\n",
        "    clfs = [knn, dt]\n",
        "    clfs_names = ['knn', 'dt']\n",
        "\n",
        "    # prepara validação cruzada\n",
        "    # faz divisão do dataset em fold partes\n",
        "    # DICA: Utilizar o método sklearn.model_selection.KFold\n",
        "    ####\n",
        "    k_folds = KFold(n_splits=folds, shuffle=True, random_state=42)\n",
        "    ####\n",
        "\n",
        "    # itera para cada classificador fazendo treino e teste\n",
        "    results = {'knn':[], 'dt':[]}\n",
        "    for c, c_name in zip(clfs, clfs_names):\n",
        "        # para cada split\n",
        "\n",
        "            # separa conjunto de treino e de teste\n",
        "            # DICA: utilizar método straKFold.split() do objeto criado na preparação\n",
        "            # da validação cruzada.\n",
        "            ####\n",
        "            X = data.drop(['target'], axis=1)\n",
        "            y = data['target'].copy()\n",
        "\n",
        "            x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=57)\n",
        "            ####\n",
        "\n",
        "            # preprocessamento\n",
        "            # DICA: Chamar a função de pré-processamento previamente produzida (preproc_fn).\n",
        "            ####\n",
        "            x_train, x_test, y_train, y_test = preprocess(x_train, x_test, y_train, y_test)\n",
        "            ####\n",
        "\n",
        "            # faz o treino do modelo\n",
        "            clf = c.fit(X=x_train, y=y_train)\n",
        "\n",
        "            # valores preditos pelo classificador\n",
        "            y_pred = clf.predict(x_test)\n",
        "\n",
        "            # rótulos verdadeiros convertidos para array\n",
        "            y_test = np.array(y_test)\n",
        "\n",
        "            # realiza predição no conjunto de teste e salva o resultado\n",
        "            # DICA: Chamar a função de avaliação previamente produzida (score_fn).\n",
        "            # A métrica calculada deve ser armazenada em \"resultado\"\n",
        "            ####\n",
        "            def scorePrecision(y_pred, y_test):\n",
        "              confusion = confusion_matrix(y_test, y_pred)\n",
        "              return metricPrecision(confusion)\n",
        "\n",
        "\n",
        "            def scoreRecall(y_pred, y_test):\n",
        "              confusion = confusion_matrix(y_test, y_pred)\n",
        "              return metricRecall(confusion)\n",
        "\n",
        "            def scoreFN(y_pred, y_test, score_name):\n",
        "              if score_name == 'Precision':\n",
        "                return scorePrecision(y_pred, y_test)\n",
        "              elif score_name == 'Recall':\n",
        "                return scoreRecall(y_pred, y_test)\n",
        "              else:\n",
        "                return 'Função de avaliação não identificada.'\n",
        "            ####\n",
        "            resultado = scoreFN(y_pred, y_test, score_name)\n",
        "            results[c_name].append(resultado)\n",
        "\n",
        "    if not plot:\n",
        "        return {'results': results, 'clfs':clfs}\n",
        "    # faz o plot de desempenho dos classificadores\n",
        "    plt.figure(figsize=(8,8))\n",
        "    plt.bar(range(1, len(clfs)+1), [mean(results[name]) for name in clfs_names],\n",
        "                                yerr=[std(results[name]) for name in clfs_names])\n",
        "    plt.xticks(range(1, len(clfs)+1), clfs_names, rotation=45)\n",
        "    title = 'Desempenho dos classificadores - %s'%(score_name)\n",
        "    plt.title(title)\n",
        "    plt.show()\n",
        "\n",
        "    return {'results': results, 'clfs':clfs}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d-MZPSb4Ya9U"
      },
      "source": [
        "---\n",
        "\n",
        "### Questão 04.\n",
        "\n",
        "Utilizar os 2 procedimentos de amostragem para estimação do desempenho:\n",
        "- 10-fold Cross Validation;\n",
        "- Leave-one-out;\n",
        "\n",
        "Para o dataset escolhido, executar os 2 procedimentos acima para estimar o desempenho.\n",
        "\n",
        "> **DICA:** Você pode utilizar a função *classificacao* já disponível apenas ajustando o parâmetro *folds*."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aTib3VxtYviF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9095421-3a34-48e7-fe7d-0552eb144441"
      },
      "source": [
        "# Ajustando o parametro folds para o 10-fold Cross Validation:\n",
        "\n",
        "resultado_10fold = classificacao(df, columns=[0, 1, 2], target=3, preproc_fn=preprocess, score_fn=metricPrecision, score_name='Precision', folds=10, plot=False)\n",
        "\n",
        "resultado_10fold"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'results': {'knn': [0.9715909090909091], 'dt': [0.8585858585858586]},\n",
              " 'clfs': [KNeighborsClassifier(n_neighbors=3),\n",
              "  DecisionTreeClassifier(min_samples_split=56)]}"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ajustando o parametro folds para o Leave-one-out:\n",
        "\n",
        "resultado_Loo = classificacao(df, columns=[0, 1, 2], target=3, preproc_fn=preprocess, score_fn=metricRecall, score_name='Recall', folds=569, plot=False)\n",
        "\n",
        "resultado_Loo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NjAIJKrUeabz",
        "outputId": "80de00f5-c726-4326-e54a-143c2820105e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'results': {'knn': [0.9884393063583815], 'dt': [0.9884393063583815]},\n",
              " 'clfs': [KNeighborsClassifier(n_neighbors=3),\n",
              "  DecisionTreeClassifier(min_samples_split=56)]}"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    }
  ]
}